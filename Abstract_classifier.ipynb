{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from helper_functions import calculate_results\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\"\n",
    "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising training sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###24293578\\n',\n",
       " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
       " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
       " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
       " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
       " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
       " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
       " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
       " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
       " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
       " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
       " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
       " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
       " '\\n',\n",
       " '###24854809\\n',\n",
       " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
       " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
       " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
       " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
       " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lines = get_lines(data_dir + \"train.txt\")\n",
    "train_lines[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that every new abstract begins with an id, starting with a \"###\".\n",
    "Also, at the end of every abstract, there is a \"\\n\".\n",
    "The target and text for every line are separated by \"\\t\".\n",
    "\n",
    "So, let's write a function that will preprocess these abstracts and return to us a DataFrame revealing certain features of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_with_line_numbers(filename):\n",
    "    input_lines = get_lines(filename)\n",
    "    abstract_lines = \"\"\n",
    "    abstract_samples = []\n",
    "\n",
    "    for line in input_lines:\n",
    "        if line.startswith(\"###\"):\n",
    "            abstract_id = line\n",
    "            abstract_lines = \"\"\n",
    "        elif line.isspace():\n",
    "            abstract_line_split = abstract_lines.splitlines()\n",
    "\n",
    "            for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
    "                line_data = {}\n",
    "                target_text_split = abstract_line.split(\"\\t\")\n",
    "                line_data[\"target\"] = target_text_split[0]\n",
    "                line_data[\"text\"] = target_text_split[1].lower()\n",
    "                line_data[\"line_number\"] = abstract_line_number\n",
    "                line_data[\"total_lines\"] = len(abstract_line_split) - 1\n",
    "                abstract_samples.append(line_data)\n",
    "\n",
    "        else:\n",
    "            abstract_lines += line\n",
    "    return abstract_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 246 ms, sys: 92.1 ms, total: 338 ms\n",
      "Wall time: 453 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(180040, 30212, 30135)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
    "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\")\n",
    "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
    "len(train_samples), len(val_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>there was a clinically relevant reduction in t...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>the mean difference between treatment arms ( @...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>further , there was a clinically relevant redu...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>these differences remained significant at @ we...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>the outcome measures in rheumatology clinical ...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>emotional eating is associated with overeating...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>yet , empirical evidence for individual ( trai...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text  \\\n",
       "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
       "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
       "2       METHODS  outcome measures included pain reduction and i...   \n",
       "3       METHODS  pain was assessed using the visual analog pain...   \n",
       "4       METHODS  secondary outcome measures included the wester...   \n",
       "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
       "6       RESULTS  there was a clinically relevant reduction in t...   \n",
       "7       RESULTS  the mean difference between treatment arms ( @...   \n",
       "8       RESULTS  further , there was a clinically relevant redu...   \n",
       "9       RESULTS  these differences remained significant at @ we...   \n",
       "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
       "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
       "12   BACKGROUND  emotional eating is associated with overeating...   \n",
       "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
       "\n",
       "    line_number  total_lines  \n",
       "0             0           11  \n",
       "1             1           11  \n",
       "2             2           11  \n",
       "3             3           11  \n",
       "4             4           11  \n",
       "5             5           11  \n",
       "6             6           11  \n",
       "7             7           11  \n",
       "8             8           11  \n",
       "9             9           11  \n",
       "10           10           11  \n",
       "11           11           11  \n",
       "12            0           10  \n",
       "13            1           10  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_samples)\n",
    "val_df = pd.DataFrame(val_samples)\n",
    "test_df = pd.DataFrame(test_samples)\n",
    "train_df.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.countplot(train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180040, 30212, 30135)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = train_df[\"text\"].tolist()\n",
    "val_sentences = val_df[\"text\"].tolist()\n",
    "test_sentences = test_df[\"text\"].tolist()\n",
    "len(train_sentences), len(val_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's encode our target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1,1))\n",
    "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "train_labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, ..., 4, 1, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
    "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
    "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
    "\n",
    "train_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(label_encoder.classes_)\n",
    "class_names = label_encoder.classes_\n",
    "num_classes, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Baseline model involving Naive-Baye's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tf-idf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tf-idf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tf-idf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model_0 = Pipeline([\n",
    "    (\"tf-idf\", TfidfVectorizer()),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "model_0.fit(X=train_sentences, y=train_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7218323844829869"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.score(X=val_sentences, y=val_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.1832384482987,\n",
       " 'precision': 0.7186466952323352,\n",
       " 'recall': 0.7218323844829869,\n",
       " 'f1': 0.6989250353450294}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_preds = model_0.predict(val_sentences)\n",
    "\n",
    "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Model_1 based upon token and character level embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will create embeddings for tokens and characters. We will use Unviersal Sentence Encoder for token level encoding and Tensorflow's TextVectorizer for char level encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Token Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
    "output_seq_len = int(np.percentile(sent_lens, 95))\n",
    "max_tokens=68000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 18:54:29.103021: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-09 18:54:29.104727: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-07-09 18:54:33.002374: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-07-09 18:54:33.029933: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        trainable=False,\n",
    "                                        name=\"universal_sentence_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random training sentence:\n",
      "however , only exercise improved muscle strength and balance .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 18:54:34.048469: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence after embedding:\n",
      "[ 0.02023723 -0.06655328 -0.04662736  0.04446952 -0.0239982   0.08206777\n",
      " -0.01637951  0.0041658  -0.00413393  0.08133954 -0.04421332  0.03309486\n",
      " -0.01464748 -0.01830733  0.04156832  0.05579033 -0.04290242 -0.03267976\n",
      "  0.06991226  0.02285956  0.08189807  0.04624748 -0.02950945  0.01741698\n",
      "  0.05157929 -0.00722864 -0.04421993  0.01478398  0.03570337 -0.04676574] (truncated output)...\n",
      "\n",
      "Length of sentence embedding:\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "# Test out the embedding on a random sentence\n",
    "random_training_sentence = random.choice(train_sentences)\n",
    "print(f\"Random training sentence:\\n{random_training_sentence}\\n\")\n",
    "use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n",
    "print(f\"Sentence after embedding:\\n{use_embedded_sentence[0][:30]} (truncated output)...\\n\")\n",
    "print(f\"Length of sentence embedding:\\n{len(use_embedded_sentence[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Character level embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_chars(text):\n",
    "    return \" \".join(list(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
    "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
    "test_chars = [split_chars(sentence) for sentence in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_seq_char_len = int(np.percentile([len(char_sent) for char_sent in train_sentences], 95))\n",
    "output_seq_char_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 18:54:36.442595: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
    "NUM_CHAR_TOKENS = len(alphabet) + 2 #space and OOV token\n",
    "char_vectorizer = TextVectorization(max_tokens = NUM_CHAR_TOKENS, output_sequence_length = output_seq_char_len, standardize=\"lower_and_strip_punctuation\", name=\"char_vectorizer\")\n",
    "char_vectorizer.adapt(train_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different characters in character vocab: 28\n",
      "5 most common characters: ['', '[UNK]', 'e', 't', 'i']\n",
      "5 least common characters: ['k', 'x', 'z', 'q', 'j']\n"
     ]
    }
   ],
   "source": [
    "# Check character vocabulary characteristics\n",
    "char_vocab = char_vectorizer.get_vocabulary()\n",
    "print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n",
    "print(f\"5 most common characters: {char_vocab[:5]}\")\n",
    "print(f\"5 least common characters: {char_vocab[-5:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embed = layers.Embedding(input_dim=NUM_CHAR_TOKENS, output_dim=25, mask_zero=False, name=\"char_embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n",
    "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
    "token_output = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
    "token_model = tf.keras.Model(inputs=token_inputs, outputs=token_output)\n",
    "\n",
    "char_input = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
    "char_vectors = char_vectorizer(char_input)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings)\n",
    "char_model = tf.keras.Model(inputs = char_input, outputs = char_bi_lstm)\n",
    "\n",
    "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output, char_model.output])\n",
    "\n",
    "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
    "combined_dense = layers.Dense(200, activation=\"relu\")(combined_dropout)\n",
    "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
    "\n",
    "output_layer = layers.Dense(num_classes, activation=\"softmax\")(final_dropout)\n",
    "\n",
    "model_1 = tf.keras.Model(inputs=[token_model.input, char_model.input], outputs=output_layer, name=\"model_1_token_char_embeddings\")\n",
    "\n",
    "model_1.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars))\n",
    "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)\n",
    "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels))\n",
    "\n",
    "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
    "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
    "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
    "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 18:54:45.433459: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-09 18:54:45.778189: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-09 18:54:45.849648: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-09 18:54:46.699444: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-09 18:54:46.716049: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562/562 [==============================] - ETA: 0s - loss: 0.9471 - accuracy: 0.6222"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 18:56:11.295034: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-09 18:56:11.485740: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-09 18:56:11.493596: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562/562 [==============================] - 99s 169ms/step - loss: 0.9471 - accuracy: 0.6222 - val_loss: 0.7904 - val_accuracy: 0.6975\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 100s 177ms/step - loss: 0.7691 - accuracy: 0.7024 - val_loss: 0.7245 - val_accuracy: 0.7271\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 103s 183ms/step - loss: 0.7423 - accuracy: 0.7152 - val_loss: 0.6965 - val_accuracy: 0.7364\n",
      "CPU times: user 4min 31s, sys: 1min 26s, total: 5min 57s\n",
      "Wall time: 5min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the model on tokens and chars\n",
    "model_1_history = model_1.fit(train_char_token_dataset, # train on dataset of token and characters\n",
    "                              steps_per_epoch=int(0.1 * len(train_char_token_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data=val_char_token_dataset,\n",
    "                              validation_steps=int(0.1 * len(val_char_token_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 18:59:45.559379: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-09 18:59:45.812758: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-09 18:59:45.823179: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 109s 114ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 73.59658413875282,\n",
       " 'precision': 0.7342370422782746,\n",
       " 'recall': 0.7359658413875282,\n",
       " 'f1': 0.7333548687980066}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_pred_probs = model_1.predict(val_char_token_dataset)\n",
    "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
    "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                    y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model_2: Char and Token Embeddings + Positional Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on with our previous model, we can see that every abstract has a specific order of components. For example, OBJECTIVE of any abstract will come before RESULT. We can leverage this property and use it as another input to feed our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     15000\n",
       "1     15000\n",
       "2     15000\n",
       "3     15000\n",
       "4     14992\n",
       "5     14949\n",
       "6     14758\n",
       "7     14279\n",
       "8     13346\n",
       "9     11981\n",
       "10    10041\n",
       "11     7892\n",
       "12     5853\n",
       "13     4152\n",
       "14     2835\n",
       "15     1861\n",
       "16     1188\n",
       "17      751\n",
       "18      462\n",
       "19      286\n",
       "20      162\n",
       "21      101\n",
       "22       66\n",
       "23       33\n",
       "24       22\n",
       "25       14\n",
       "26        7\n",
       "27        4\n",
       "28        3\n",
       "29        1\n",
       "30        1\n",
       "Name: line_number, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.line_number.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.line_number.plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_line_numbers_one_hot = tf.one_hot(train_df.line_number.to_numpy(), depth = 15)\n",
    "val_line_numbers_one_hot = tf.one_hot(val_df.line_number.to_numpy(), depth = 15)\n",
    "test_line_numbers_one_hot = tf.one_hot(test_df.line_number.to_numpy(), depth = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.total_lines.plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(train_df.total_lines, 98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total_lines_one_hot = tf.one_hot(train_df[\"total_lines\"].to_numpy(), depth=20)\n",
    "val_total_lines_one_hot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth=20)\n",
    "test_total_lines_one_hot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 411 ms, sys: 92.2 ms, total: 504 ms\n",
      "Wall time: 626 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 1. Token Inputs\n",
    "token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_inputs\")\n",
    "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
    "token_outputs = layers.Dense(128, activation='relu')(token_embeddings)\n",
    "token_model = tf.keras.Model(inputs=token_inputs, outputs=token_outputs)\n",
    "\n",
    "# 2. Char Inputs\n",
    "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_inputs\")\n",
    "char_vectors = char_vectorizer(char_inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "char_bi_lstm = layers.Bidirectional(layers.LSTM(32))(char_embeddings)\n",
    "char_model = tf.keras.Model(inputs=char_inputs, outputs=char_bi_lstm)\n",
    "\n",
    "# 3. Line number inputs\n",
    "line_number_inputs = layers.Input(shape=(15,), dtype=tf.int32, name=\"line_number_input\")\n",
    "x = layers.Dense(32, activation=\"relu\")(line_number_inputs)\n",
    "line_number_model = tf.keras.Model(inputs= line_number_inputs, outputs=x)\n",
    "\n",
    "# 4. Total Lines inputs\n",
    "total_lines_inputs = layers.Input(shape=(20,), dtype=tf.int32, name=\"total_lines_input\")\n",
    "y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n",
    "total_lines_model = tf.keras.Model(inputs=total_lines_inputs, outputs=y)\n",
    "\n",
    "# 5. Combining token and char embeddings\n",
    "combined_embeddings = layers.Concatenate(name = \"token_char_hybrid_embedding\")([token_model.output, char_model.output])\n",
    "z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n",
    "z = layers.Dropout(0.5)(z)\n",
    "\n",
    "# 6. Combine positional embeddings with combined token and char embeddings into a tribid embedding\n",
    "z = layers.Concatenate(name=\"token_char_positional_embedding\")([line_number_model.output, total_lines_model.output, z])\n",
    "\n",
    "output_layer = layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")(z)\n",
    "\n",
    "model_2 = tf.keras.Model(inputs=[line_number_model.input, total_lines_model.input, token_model.input, char_model.input], outputs = output_layer)\n",
    "\n",
    "model_2.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2), optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 669 ms, sys: 245 ms, total: 914 ms\n",
      "Wall time: 1.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_pos_char_token_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, train_total_lines_one_hot, train_sentences, train_chars))\n",
    "\n",
    "train_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)\n",
    "\n",
    "train_pos_char_token_dataset = tf.data.Dataset.zip((train_pos_char_token_data, train_pos_char_token_labels))\n",
    "train_pos_char_token_dataset = train_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_pos_char_token_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n",
    "                                                              val_total_lines_one_hot,\n",
    "                                                              val_sentences,\n",
    "                                                              val_chars))\n",
    "val_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
    "val_pos_char_token_dataset = tf.data.Dataset.zip((val_pos_char_token_data, val_pos_char_token_labels))\n",
    "val_pos_char_token_dataset = val_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 19:01:39.782006: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-09 19:01:40.227502: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-09 19:01:40.241157: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-09 19:01:41.435143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-09 19:01:41.451718: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562/562 [==============================] - ETA: 0s - loss: 1.0948 - accuracy: 0.7228"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 19:03:32.545680: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-09 19:03:32.804990: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-09 19:03:32.830249: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562/562 [==============================] - 132s 225ms/step - loss: 1.0948 - accuracy: 0.7228 - val_loss: 0.9884 - val_accuracy: 0.8032\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 130s 231ms/step - loss: 0.9659 - accuracy: 0.8149 - val_loss: 0.9522 - val_accuracy: 0.8268\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 134s 238ms/step - loss: 0.9493 - accuracy: 0.8226 - val_loss: 0.9415 - val_accuracy: 0.8291\n"
     ]
    }
   ],
   "source": [
    "# Fit the token, char and positional embedding model\n",
    "# %%time\n",
    "history_model_2 =model_2.fit(train_pos_char_token_dataset,\n",
    "                              steps_per_epoch=int(0.1 * len(train_pos_char_token_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data=val_pos_char_token_dataset,\n",
    "                              validation_steps=int(0.1 * len(val_pos_char_token_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 19:08:14.431461: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-09 19:08:14.979929: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-09 19:08:15.135429: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 136s 142ms/step\n",
      "CPU times: user 2min 8s, sys: 42.8 s, total: 2min 51s\n",
      "Wall time: 2min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 83.26161790017211,\n",
       " 'precision': 0.8321396124575425,\n",
       " 'recall': 0.8326161790017211,\n",
       " 'f1': 0.8313881816156524}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_2_pred_probs = model_2.predict(val_pos_char_token_dataset, verbose=1)\n",
    "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
    "model_2_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                    y_pred=model_2_preds)\n",
    "model_2_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d863b53cd71cc32646915a3d3e16c3f2ca68fc33117b6dc1b992a95d7bcb6a18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
